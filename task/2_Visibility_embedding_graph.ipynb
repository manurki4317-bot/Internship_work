{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Spike and Burst Analysis with Visibility Graphs\n",
    "\n",
    "This notebook provides a detailed workflow for analyzing electrophysiological ABF recordings.\n",
    "It goes through the following steps:\n",
    "1. Loading ABF files and concatenating sweeps\n",
    "2. Spike detection\n",
    "3. Burst detection\n",
    "4. Burst classification\n",
    "5. Saving bursts to CSV\n",
    "6. Visibility graph creation for each burst\n",
    "7. 2D and 3D embeddings of the burst graphs\n",
    "8. Visualization of spikes, bursts, and graphs\n",
    "9. Saving nodes and edges data to CSV\n",
    "This is an eplanation of the code obtained.\n",
    "To access to the original codes, download the codes from the folder named Python\n",
    "\n",

     

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Load Libraries\n",
    "\n",
    "We import all necessary libraries:\n",
    "- `pyabf`: for reading ABF files.\n",
    "- `numpy`: numerical operations and array manipulations.\n",
    "- `pandas`: handling tabular data and saving CSVs.\n",
    "- `matplotlib.pyplot`: plotting and visualization.\n",
    "- `networkx`: creating and analyzing graphs.\n",
    "- `scipy.signal.find_peaks`: detecting spikes as local maxima.\n",
    "- `sklearn.decomposition.TruncatedSVD`: computing 2D/3D embeddings from adjacency matrices.\n",
    "\n",
    "`%matplotlib widget` enables interactive plots inside Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyabf  # Reads ABF electrophysiology files\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # DataFrames and CSV handling\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import networkx as nx  # Graph creation and analysis\n",
    "from scipy.signal import find_peaks  # Spike detection\n",
    "from sklearn.decomposition import TruncatedSVD  # Embedding\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load ABF File and Concatenate Sweeps\n",
    "\n",
    "**Explanation:**\n",
    "- ABF files often contain multiple sweeps (repeated recordings).\n",
    "- We concatenate all sweeps into a **single continuous voltage vector** for simplicity.\n",
    "- `abf.dataRate` gives the sampling rate, used to create a time vector.\n",
    "- `np.concatenate([...])` merges all sweeps into one array.\n",
    "- `np.arange(len(signal)) * dt` generates a time vector in seconds aligned with the voltage signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"bursting/cell89basal.abf\"\n",
    "abf = pyabf.ABF(file_path)\n",
    "\n",
    "# Concatenate all sweeps\n",
    "signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])\n",
    "dt = 1.0 / abf.dataRate\n",
    "time = np.arange(len(signal)) * dt\n",
    "\n",
    "print(f\"File: {file_path} | sweeps: {abf.sweepCount} | total duration: {time[-1]:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Spike Detection\n",
    "\n",
    "**Explanation:**\n",
    "- Spikes are detected as peaks above a voltage threshold (here `-35 mV`).\n",
    "- `find_peaks(signal, height=threshold)` returns indices of the peaks.\n",
    "- Convert spike indices to time in seconds for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -35  # mV\n",
    "spike_indices, _ = find_peaks(signal, height=threshold)  # Spike indices\n",
    "spike_times = time[spike_indices]  # Convert indices to time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Burst Detection\n",
    "\n",
    "**Explanation:**\n",
    "- Bursts are sequences of spikes with interspike intervals (ISI) < 0.3 seconds.\n",
    "- Compute ISI with `np.diff(spike_times)`.\n",
    "- Group consecutive spikes into bursts.\n",
    "- `isi_per_spike_burst` stores ISI for each spike within a burst in milliseconds (first spike = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi = np.diff(spike_times)\n",
    "burst_threshold = 0.3\n",
    "bursts = []\n",
    "current_burst = [0]\n",
    "\n",
    "for i in range(1, len(spike_times)):\n",
    "    if isi[i-1] < burst_threshold:\n",
    "        current_burst.append(i)\n",
    "    else:\n",
    "        if len(current_burst) > 1:\n",
    "            bursts.append(current_burst)\n",
    "        current_burst = [i]\n",
    "if len(current_burst) > 1:\n",
    "    bursts.append(current_burst)\n",
    "\n",
    "print(f\"Detected {len(bursts)} bursts\")\n",
    "\n",
    "# Internal ISI in ms\n",
    "isi_per_spike_burst = np.zeros(len(spike_times))\n",
    "for burst in bursts:\n",
    "    for i, idx in enumerate(burst):\n",
    "        isi_per_spike_burst[idx] = 0 if i==0 else (spike_times[idx]-spike_times[burst[i-1]])*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Burst Classification\n",
    "\n",
    "**Explanation:**\n",
    "- Classify bursts based on minimum voltage relative to baseline around the burst.\n",
    "- Baseline = mean voltage before and after the burst.\n",
    "- Rules:\n",
    "  - Minimum > baseline → Square Wave\n",
    "  - Minimum < baseline → Parabolic\n",
    "  - Otherwise → Other\n",
    "- Store types in `burst_types` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_wave_bursts, parabolic_bursts, other_bursts = [], [], []\n",
    "burst_types = {}\n",
    "\n",
    "for i, burst in enumerate(bursts):\n",
    "    burst_mask = (time >= spike_times[burst[0]]) & (time <= spike_times[burst[-1]])\n",
    "    burst_min = np.min(signal[burst_mask])\n",
    "    prev_mean = np.mean(signal[(time > spike_times[bursts[i-1][-1]]) & (time < spike_times[burst[0]])]) if i>0 else np.nan\n",
    "    next_mean = np.mean(signal[(time > spike_times[burst[-1]]) & (time < spike_times[bursts[i+1][0]])]) if i<len(bursts)-1 else np.nan\n",
    "    inter_mean = np.nanmean([prev_mean, next_mean])\n",
    "    if burst_min > inter_mean:\n",
    "        square_wave_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Square Wave\"\n",
    "    elif burst_min < inter_mean:\n",
    "        parabolic_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Parabolic\"\n",
    "    else:\n",
    "        other_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Bursts to CSV\n",
    "\n",
    "- Save burst number, start/end times, and classification.\n",
    "- Output CSV is used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_list = []\n",
    "for idx, burst in enumerate(bursts):\n",
    "    burst_type = burst_types[tuple(burst)]\n",
    "    burst_list.append([idx+1, spike_times[burst[0]], spike_times[burst[-1]], burst_type])\n",
    "\n",
    "df_bursts_all = pd.DataFrame(burst_list, columns=[\"Burst_Number\",\"Start_Time_s\",\"End_Time_s\",\"Type\"])\n",
    "df_bursts_all.to_csv(\"burst_basic_info_cell89_all_bursts.csv\", index=False)\n",
    "df_bursts_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visibility Graphs and Embeddings\n",
    "\n",
    "**Explanation:**\n",
    "- Each burst is represented as a **visibility graph**: each spike is a node.\n",
    "- Two spikes (nodes) are connected if a straight line between them does not cross any intermediate spike.\n",
    "- `networkx` is used for graph creation.\n",
    "- Adjacency matrices of the graphs are embedded in 2D and 3D using `TruncatedSVD`.\n",
    "- Node and edge info is stored for CSV export.\n",
    "- Colors correspond to burst types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_map = {\"Square Wave\":\"blue\", \"Parabolic\":\"green\", \"Other\":\"orange\"}\n",
    "nodes_list, edges_list = [], []\n",
    "\n",
    "for b_idx, burst in enumerate(bursts):\n",
    "    burst_type = burst_types[tuple(burst)]\n",
    "    x_peaks = np.arange(len(burst))\n",
    "    y_peaks = isi_per_spike_burst[burst]\n",
    "\n",
    "    # Create visibility graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(len(burst)))\n",
    "    for a in range(len(x_peaks)):\n",
    "        for b in range(a+1, len(x_peaks)):\n",
    "            visible = True\n",
    "            for c in range(a+1,b):\n",
    "                y_line = y_peaks[b] + (y_peaks[a]-y_peaks[b])*(x_peaks[b]-x_peaks[c])/(x_peaks[b]-x_peaks[a])\n",
    "                if y_peaks[c] >= y_line:\n",
    "                    visible=False\n",
    "                    break\n",
    "            if visible:\n",
    "                G.add_edge(a,b)\n",
    "                edges_list.append([b_idx+1, burst_type, a, b])\n",
    "\n",
    "    # Compute embeddings\n",
    "    A = nx.to_numpy_array(G)\n",
    "    n_dim = min(3,A.shape[0])\n",
    "    embedding_2d = TruncatedSVD(n_components=2, random_state=42).fit_transform(A)\n",
    "    embedding_3d = TruncatedSVD(n_components=n_dim, random_state=42).fit_transform(A) if n_dim>=3 else np.zeros((len(burst),3))\n",
    "\n",
    "    for i in range(len(burst)):\n",
    "        nodes_list.append([b_idx+1, burst_type, i,\n",
    "                           embedding_2d[i,0], embedding_2d[i,1],\n",
    "                           embedding_3d[i,0], embedding_3d[i,1], embedding_3d[i,2],\n",
    "                           burst[i]])\n",
    "\n",
    "    # Plot first few bursts\n",
    "    if b_idx < 10:\n",
    "        fig = plt.figure(figsize=(12,10))\n",
    "        ax0 = fig.add_subplot(3,1,1)\n",
    "        for u,v in G.edges():\n",
    "            ax0.plot([x_peaks[u], x_peaks[v]], [y_peaks[u], y_peaks[v]], 'gray', alpha=0.5)\n",
    "        ax0.scatter(x_peaks, y_peaks, color=colors_map[burst_type], s=40)\n",
    "        ax0.set_title(f\"Burst {b_idx+1} Visibility graph ({burst_type})\")\n",
    "        ax0.set_xlabel(\"Spike index\")\n",
    "        ax0.set_ylabel(\"ISI (ms)\")\n",
    "        ax0.grid(True)\n",
    "\n",
    "        ax1 = fig.add_subplot(3,1,2)\n",
    "        for i in range(len(burst)):\n",
    "            ax1.scatter(embedding_2d[i,0], embedding_2d[i,1], color=colors_map[burst_type], s=50)\n",
    "            ax1.text(embedding_2d[i,0]+0.01, embedding_2d[i,1]+0.01, str(i), fontsize=8)\n",
    "        for u,v in G.edges():\n",
    "            ax1.plot([embedding_2d[u,0], embedding_2d[v,0]], [embedding_2d[u,1], embedding_2d[v,1]], 'r-', alpha=0.3)\n",
    "        ax1.set_title(f\"Burst {b_idx+1} Embedding 2D\")\n",
    "        ax1.grid(True)\n",
    "\n",
    "        if embedding_3d is not None:\n",
    "            ax2 = fig.add_subplot(3,1,3, projection='3d')\n",
    "            for i in range(len(burst)):\n",
    "                ax2.scatter(embedding_3d[i,0], embedding_3d[i,1], embedding_3d[i,2], color=colors_map[burst_type], s=40)\n",
    "                ax2.text(embedding_3d[i,0], embedding_3d[i,1], embedding_3d[i,2], str(i), fontsize=8)\n",
    "            for u,v in G.edges():\n",
    "                ax2.plot([embedding_3d[u,0], embedding_3d[v,0]], [embedding_3d[u,1], embedding_3d[v,1]], [embedding_3d[u,2], embedding_3d[v,2]], 'r-', alpha=0.3)\n",
    "            ax2.set_title(f\"Burst {b_idx+1} Embedding 3D\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Nodes and Edges CSV\n",
    "\n",
    "Explanation:\n",
    "- Each node contains burst number, type, node index, 2D/3D coordinates, and global spike index.\n",
    "- Each edge contains burst number, type, and indices of connected nodes.\n",
    "- CSV files are useful for graph-based analyses outside Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = pd.DataFrame(nodes_list, columns=[\"Burst_Number\",\"Type\",\"Node_ID\",\n",
    "                                             \"X_2D\",\"Y_2D\",\"X_3D\",\"Y_3D\",\"Z_3D\",\n",
    "                                             \"Spike_Global_Index\"])\n",
    "df_edges = pd.DataFrame(edges_list, columns=[\"Burst_Number\",\"Type\",\"Node1_ID\",\"Node2_ID\"])\n",
    "\n",
    "df_nodes.to_csv(\"burst_nodes_all.csv\", index=False)\n",
    "df_edges.to_csv(\"burst_edges_all.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary\n",
    "\n",
    "- This notebook performs **spike detection**, **burst detection**, **burst classification**, **visibility graph creation**, and **embedding**.\n",
    "- CSV outputs allow further quantitative analysis.\n",
    "- Interactive plots provide visual inspection of spike patterns, burst types, and network structures.\n",
    "- This pipeline can be applied to multiple ABF files by iterating over them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
