{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Spike and Burst Analysis with Visibility Graphs\n",
    "This notebook provides a detailed workflow for analyzing electrophysiological ABF recordings. It goes through the following steps:\n",
    "\n",
    "- Loading ABF files and concatenating sweeps\n",
    "- Spike detection\n",
    "- Burst detection\n",
    "- Burst classification\n",
    "- Saving bursts to CSV\n",
    "- Visibility graph creation for each burst\n",
    "- 2D and 3D embeddings of the burst graphs\n",
    "- Visualization of spikes, bursts, and graphs\n",
    "- Saving nodes and edges data to CSV\n",
    "\n",
    "Each section includes detailed explanations of the code functionality and rationale behind each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Screenshot\n",
    "This screenshot shows an example of the spike and burst analysis:\n",
    "\n",
    "![Spike and Burst Analysis](Captura_de_pantalla_2025-10-02_080635.png)\n",
    "\n",
    "> Make sure the image file is uploaded to the same folder as the notebook, or adjust the path accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyabf  # Reads ABF electrophysiology files\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # DataFrames and CSV handling\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "import networkx as nx  # Graph creation and analysis\n",
    "from scipy.signal import find_peaks  # Spike detection\n",
    "from sklearn.decomposition import TruncatedSVD  # Embedding\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"bursting/cell89basal.abf\"\n",
    "abf = pyabf.ABF(file_path)\n",
    "\n",
    "# Concatenate all sweeps\n",
    "signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])\n",
    "dt = 1.0 / abf.dataRate\n",
    "time = np.arange(len(signal)) * dt\n",
    "\n",
    "print(f\"File: {file_path} | sweeps: {abf.sweepCount} | total duration: {time[-1]:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -35  # mV\n",
    "spike_indices, _ = find_peaks(signal, height=threshold)\n",
    "spike_times = time[spike_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isi = np.diff(spike_times)\n",
    "burst_threshold = 0.3\n",
    "bursts = []\n",
    "current_burst = [0]\n",
    "\n",
    "for i in range(1, len(spike_times)):\n",
    "    if isi[i-1] < burst_threshold:\n",
    "        current_burst.append(i)\n",
    "    else:\n",
    "        if len(current_burst) > 1:\n",
    "            bursts.append(current_burst)\n",
    "        current_burst = [i]\n",
    "if len(current_burst) > 1:\n",
    "    bursts.append(current_burst)\n",
    "\n",
    "print(f\"Detected {len(bursts)} bursts\")\n",
    "\n",
    "isi_per_spike_burst = np.zeros(len(spike_times))\n",
    "for burst in bursts:\n",
    "    for i, idx in enumerate(burst):\n",
    "        isi_per_spike_burst[idx] = 0 if i==0 else (spike_times[idx]-spike_times[burst[i-1]])*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_wave_bursts, parabolic_bursts, other_bursts = [], [], []\n",
    "burst_types = {}\n",
    "\n",
    "for i, burst in enumerate(bursts):\n",
    "    burst_mask = (time >= spike_times[burst[0]]) & (time <= spike_times[burst[-1]])\n",
    "    burst_min = np.min(signal[burst_mask])\n",
    "    prev_mean = np.mean(signal[(time > spike_times[bursts[i-1][-1]]) & (time < spike_times[burst[0]])]) if i>0 else np.nan\n",
    "    next_mean = np.mean(signal[(time > spike_times[burst[-1]]) & (time < spike_times[bursts[i+1][0]])]) if i < len(bursts)-1 else np.nan\n",
    "    inter_mean = np.nanmean([prev_mean, next_mean])\n",
    "    \n",
    "    if burst_min > inter_mean:\n",
    "        square_wave_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Square Wave\"\n",
    "    elif burst_min < inter_mean:\n",
    "        parabolic_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Parabolic\"\n",
    "    else:\n",
    "        other_bursts.append(burst)\n",
    "        burst_types[tuple(burst)] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_list = []\n",
    "for idx, burst in enumerate(bursts):\n",
    "    burst_type = burst_types[tuple(burst)]\n",
    "    burst_list.append([idx+1, spike_times[burst[0]], spike_times[burst[-1]], burst_type])\n",
    "\n",
    "df_bursts_all = pd.DataFrame(burst_list, columns=[\"Burst_Number\",\"Start_Time_s\",\"End_Time_s\",\"Type\"])\n",
    "df_bursts_all.to_csv(\"burst_basic_info_cell89_all_bursts.csv\", index=False)\n",
    "df_bursts_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_map = {\"Square Wave\":\"blue\", \"Parabolic\":\"green\", \"Other\":\"orange\"}\n",
    "nodes_list, edges_list = [], []\n",
    "\n",
    "for b_idx, burst in enumerate(bursts):\n",
    "    burst_type = burst_types[tuple(burst)]\n",
    "    x_peaks = np.arange(len(burst))\n",
    "    y_peaks = isi_per_spike_burst[burst]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(len(burst)))\n",
    "    for a in range(len(x_peaks)):\n",
    "        for b in range(a+1, len(x_peaks)):\n",
    "            visible = True\n",
    "            for c in range(a+1,b):\n",
    "                y_line = y_peaks[b] + (y_peaks[a]-y_peaks[b])*(x_peaks[b]-x_peaks[c])/(x_peaks[b]-x_peaks[a])\n",
    "                if y_peaks[c] >= y_line:\n",
    "                    visible=False\n",
    "                    break\n",
    "            if visible:\n",
    "                G.add_edge(a,b)\n",
    "                edges_list.append([b_idx+1, burst_type, a, b])\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    n_dim = min(3,A.shape[0])\n",
    "    embedding_2d = TruncatedSVD(n_components=2, random_state=42).fit_transform(A)\n",
    "    embedding_3d = TruncatedSVD(n_components=n_dim, random_state=42).fit_transform(A) if n_dim>=3 else np.zeros((len(burst),3))\n",
    "\n",
    "    for i in range(len(burst)):\n",
    "        nodes_list.append([b_idx+1, burst_type, i,\n",
    "                           embedding_2d[i,0], embedding_2d[i,1],\n",
    "                           embedding_3d[i,0], embedding_3d[i,1], embedding_3d[i,2],\n",
    "                           burst[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = pd.DataFrame(nodes_list, columns=[\"Burst_Number\",\"Type\",\"Node_ID\",\n",
    "                                             \"X_2D\",\"Y_2D\",\"X_3D\",\"Y_3D\",\"Z_3D\",\n",
    "                                             \"Spike_Global_Index\"])\n",
    "df_edges = pd.DataFrame(edges_list, columns=[\"Burst_Number\",\"Type\",\"Node1_ID\",\"Node2_ID\"])\n",
    "\n",
    "df_nodes.to_csv(\"burst_nodes_all.csv\", index=False)\n",
    "df_edges.to_csv(\"burst_edges_all.csv\", index=False)\n",
    "print(\"CSV files for nodes and edges saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 10
}
