{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified Electrophysiology Analysis Pipeline\n",
    "\n",
    "This notebook processes ABF files to detect spikes and bursts, classify bursts, extract normalized bursts for shapelet learning, train a shapelet model, perform UMAP embedding, and detect conflict regions between burst types.\n",
    "\n",
    "All sections include comments outside the code explaining their purpose."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Imports and parameters\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyabf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks, hilbert\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.interpolate import interp1d\n",
    "from numpy.linalg import lstsq\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.shapelets import LearningShapelets\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import cm\n",
    "\n",
    "# Parameters\n",
    "folder_path = \"bursting\"\n",
    "threshold = -35\n",
    "burst_threshold = 0.3\n",
    "fs = 10000\n",
    "dt = 1/fs"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Helper functions for spikes and bursts\n",
    "def normalize_y(signal_segment):\n",
    "    return (signal_segment - np.mean(signal_segment)) / np.std(signal_segment)\n",
    "\n",
    "def rescale_x(time_segment, signal_segment, n_points=100):\n",
    "    f = interp1d(np.linspace(0, 1, len(signal_segment)), signal_segment)\n",
    "    return f(np.linspace(0, 1, n_points))\n",
    "\n",
    "def detect_spikes(signal, threshold=-35):\n",
    "    spike_indices, _ = find_peaks(signal, height=threshold)\n",
    "    return spike_indices\n",
    "\n",
    "def detect_bursts(spike_times, burst_threshold=0.3):\n",
    "    isi = np.diff(spike_times)\n",
    "    bursts = []\n",
    "    current_burst = [spike_times[0]]\n",
    "    for i in range(1, len(isi)):\n",
    "        if isi[i-1] < burst_threshold:\n",
    "            current_burst.append(spike_times[i])\n",
    "        else:\n",
    "            if len(current_burst) > 1:\n",
    "                bursts.append((current_burst[0], current_burst[-1]))\n",
    "            current_burst = [spike_times[i]]\n",
    "    if len(current_burst) > 1:\n",
    "        bursts.append((current_burst[0], current_burst[-1]))\n",
    "    return bursts"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Burst classification\n",
    "def classify_bursts(bursts, signal, time):\n",
    "    square_wave_bursts = []\n",
    "    parabolic_bursts = []\n",
    "    other_bursts = []\n",
    "\n",
    "    for i, (burst_start, burst_end) in enumerate(bursts):\n",
    "        burst_mask = (time >= burst_start) & (time <= burst_end)\n",
    "        burst_min = np.min(signal[burst_mask])\n",
    "\n",
    "        prev_mean = np.mean(signal[(time > bursts[i-1][1]) & (time < burst_start)]) if i>0 else np.nan\n",
    "        next_mean = np.mean(signal[(time > burst_end) & (time < bursts[i+1][0])]) if i < len(bursts)-1 else np.nan\n",
    "        inter_mean = np.nanmean([prev_mean, next_mean])\n",
    "\n",
    "        if burst_min > inter_mean:\n",
    "            square_wave_bursts.append((burst_start, burst_end))\n",
    "        elif burst_min < inter_mean:\n",
    "            parabolic_bursts.append((burst_start, burst_end))\n",
    "        else:\n",
    "            other_bursts.append((burst_start, burst_end))\n",
    "    return square_wave_bursts, parabolic_bursts, other_bursts"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract normalized bursts for shapelet learning\n",
    "def extract_normalized_bursts(burst_list, signal, time, n_points=100):\n",
    "    normalized_bursts = []\n",
    "    for start, end in burst_list:\n",
    "        mask = (time >= start) & (time <= end)\n",
    "        s_rescaled = rescale_x(time[mask], signal[mask], n_points)\n",
    "        s_normalized = normalize_y(s_rescaled)\n",
    "        normalized_bursts.append(s_normalized)\n",
    "    return normalized_bursts"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
