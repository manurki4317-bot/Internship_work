import pyabf
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
%matplotlib widget

# Load data
file_path = "bursting/cell89basal.abf"
abf = pyabf.ABF(file_path)

# Concatenate sweeps
signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])
dt = 1.0 / abf.dataRate
time = np.arange(len(signal)) * dt

# Spike detection
threshold = -35  # mV
spike_indices, _ = find_peaks(signal, height=threshold)
spike_times = time[spike_indices]

# Burst detection 
isi = np.diff(spike_times)
burst_threshold = 0.3  # s

bursts = []
current_burst = [spike_times[0]]
for i in range(1, len(isi)):
    if isi[i-1] < burst_threshold:
        current_burst.append(spike_times[i])
    else:
        if len(current_burst) > 1:
            bursts.append(current_burst)
        current_burst = [spike_times[i]]
if len(current_burst) > 1:
    bursts.append(current_burst)

print(f"Total detected bursts: {len(bursts)}")

# Plot the first 10 bursts (one per figure)
n_bursts_to_plot = min(10, len(bursts))

for i in range(n_bursts_to_plot):
    burst = bursts[i]

    # Mask to crop the signal in the burst window
    mask = (time >= burst[0]) & (time <= burst[-1])
    t_burst = time[mask]
    s_burst = signal[mask]

    # Burst peaks (use spike_indices within the interval)
    burst_peak_mask = (spike_times >= burst[0]) & (spike_times <= burst[-1])
    burst_spike_times = spike_times[burst_peak_mask]
    burst_spike_values = signal[spike_indices][burst_peak_mask]

    # Create figure for each burst
    plt.figure(figsize=(8, 3))
    plt.plot(t_burst, s_burst, lw=0.8, color="black")
    plt.plot(burst_spike_times, burst_spike_values, "ro", markersize=3)
    plt.plot(burst_spike_times, burst_spike_values, "r-", lw=1)

    plt.xlabel("Time (s)")
    plt.ylabel("Voltage (mV)")
    plt.title(f"Burst {i+1}")
    plt.tight_layout()
    plt.show()





import pyabf
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from scipy.interpolate import interp1d

# Load data
file_path = "bursting/cell89basal.abf"
abf = pyabf.ABF(file_path)

# Concatenate sweeps
signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])
dt = 1.0 / abf.dataRate
time = np.arange(len(signal)) * dt

# Spike detection
threshold = -35  # mV
spike_indices, _ = find_peaks(signal, height=threshold)
spike_times = time[spike_indices]

# Burst detection
isi = np.diff(spike_times)
burst_threshold = 0.3  # s

bursts = []
current_burst = [spike_times[0]]
for i in range(1, len(isi)):
    if isi[i-1] < burst_threshold:
        current_burst.append(spike_times[i])
    else:
        if len(current_burst) > 1:
            bursts.append(current_burst)
        current_burst = [spike_times[i]]
if len(current_burst) > 1:
    bursts.append(current_burst)

print(f"Total detected bursts: {len(bursts)}")

# Normalization functions
def normalize_y(signal_segment):
    # Normalize amplitude using z-score
    return (signal_segment - np.mean(signal_segment)) / np.std(signal_segment)

def rescale_x(time_segment, signal_segment, n_points=100):
    # Rescale duration (interpolate to n_points)
    f = interp1d(np.linspace(0, 1, len(signal_segment)), signal_segment)
    return f(np.linspace(0, 1, n_points))

# Plot the first 10 normalized bursts 
n_bursts_to_plot = min(10, len(bursts))

for i in range(n_bursts_to_plot):
    burst = bursts[i]

    # Crop the burst signal
    mask = (time >= burst[0]) & (time <= burst[-1])
    t_burst = time[mask]
    s_burst = signal[mask]

    # Normalize in duration (X)
    s_rescaled = rescale_x(t_burst, s_burst, n_points=100)

    # Normalize in amplitude (Y)
    s_normalized = normalize_y(s_rescaled)

    # Plot normalized burst
    plt.figure(figsize=(6, 3))
    plt.plot(np.linspace(0, 1, 100), s_normalized, "k-")
    plt.title(f"Burst {i+1} (normalized)")
    plt.xlabel("Time normalized")
    plt.ylabel("Normalized amplitude")
    plt.tight_layout()
    plt.show()





import pyabf
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from scipy.interpolate import interp1d

# Load data
file_path = "bursting/cell89basal.abf"
abf = pyabf.ABF(file_path)

signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])
dt = 1.0 / abf.dataRate
time = np.arange(len(signal)) * dt

# Spike detection 
threshold = -35  # mV
spike_indices, _ = find_peaks(signal, height=threshold)
spike_times = time[spike_indices]

# Burst detection 
isi = np.diff(spike_times)
burst_threshold = 0.3  # s

bursts = []
current_burst = [spike_times[0]]
for i in range(1, len(isi)):
    if isi[i-1] < burst_threshold:
        current_burst.append(spike_times[i])
    else:
        if len(current_burst) > 1:
            bursts.append((current_burst[0], current_burst[-1]))
        current_burst = [spike_times[i]]
if len(current_burst) > 1:
    bursts.append((current_burst[0], current_burst[-1]))

# Burst classification 
square_wave_bursts = []
parabolic_bursts = []
other_bursts = []

for i, (burst_start, burst_end) in enumerate(bursts):
    burst_mask = (time >= burst_start) & (time <= burst_end)
    burst_min = np.min(signal[burst_mask])

    prev_mean = np.mean(signal[(time > bursts[i-1][1]) & (time < burst_start)]) if i > 0 else np.nan
    next_mean = np.mean(signal[(time > burst_end) & (time < bursts[i+1][0])]) if i < len(bursts)-1 else np.nan
    inter_mean = np.nanmean([prev_mean, next_mean])

    if burst_min > inter_mean:
        square_wave_bursts.append((burst_start, burst_end))
    elif burst_min < inter_mean:
        parabolic_bursts.append((burst_start, burst_end))
    else:
        other_bursts.append((burst_start, burst_end))

# Normalization functions 
def normalize_y(signal_segment):
    return (signal_segment - np.mean(signal_segment)) / np.std(signal_segment)

def rescale_x(time_segment, signal_segment, n_points=100):
    f = interp1d(np.linspace(0, 1, len(signal_segment)), signal_segment)
    return f(np.linspace(0, 1, n_points))

# Function to overlay bursts 
def overlay_bursts(burst_list, burst_type, n=3):
    if len(burst_list) == 0:
        print(f"No bursts of type {burst_type} to plot.")
        return

    n_to_plot = min(n, len(burst_list))
    plt.figure(figsize=(6, 3))
    
    for i in range(n_to_plot):
        start, end = burst_list[i]
        mask = (time >= start) & (time <= end)
        t_burst = time[mask]
        s_burst = signal[mask]

        # Normalize
        s_rescaled = rescale_x(t_burst, s_burst, n_points=100)
        s_normalized = normalize_y(s_rescaled)

        plt.plot(np.linspace(0, 1, 100), s_normalized, lw=1, alpha=0.7, label=f'Burst {i+1}')

    plt.title(f"{burst_type} Bursts Overlay (normalized)")
    plt.xlabel("Time normalized")
    plt.ylabel("Normalized amplitude")
    plt.legend()
    plt.tight_layout()
    plt.show()

overlay_bursts(square_wave_bursts, "Square Wave", n=3)
overlay_bursts(parabolic_bursts, "Parabolic", n=3)
overlay_bursts(other_bursts, "Other", n=3)





import pyabf
import numpy as np
from scipy.signal import find_peaks
from scipy.interpolate import interp1d

# Preprocessing functions 
def normalize_y(signal_segment):
    # Normalize the amplitude of a signal segment using z-score.
    # This ensures all bursts have comparable amplitudes regardless of absolute voltage.
    
    return (signal_segment - np.mean(signal_segment)) / np.std(signal_segment)

def rescale_x(time_segment, signal_segment, n_points=100):
    #Rescale the time axis of a signal segment.
    #Interpolates the burst to `n_points` so all bursts have the same length.
    #Useful for machine learning applications like shapelet extraction.
    
    f = interp1d(np.linspace(0, 1, len(signal_segment)), signal_segment)
    return f(np.linspace(0, 1, n_points))

def detect_spikes(signal, threshold=-35):
    # Detect spikes in the signal using a voltage threshold.
    # Returns the indices of peaks above the threshold.
   
    spike_indices, _ = find_peaks(signal, height=threshold)
    return spike_indices

def detect_bursts(spike_times, burst_threshold=0.3):
    # Detect bursts based on inter-spike interval (ISI).
    # Spikes closer than `burst_threshold` seconds are grouped into the same burst.
    # Returns a list of tuples (burst_start_time, burst_end_time).

    isi = np.diff(spike_times)
    bursts = []
    current_burst = [spike_times[0]]
    for i in range(1, len(isi)):
        if isi[i-1] < burst_threshold:
            current_burst.append(spike_times[i])
        else:
            if len(current_burst) > 1:  # Only consider bursts with more than one spike
                bursts.append((current_burst[0], current_burst[-1]))
            current_burst = [spike_times[i]]
    if len(current_burst) > 1:
        bursts.append((current_burst[0], current_burst[-1]))
    return bursts

def classify_bursts(bursts, signal, time):    
    # Classify bursts into three types:
    # 1. Square Wave: burst_min > surrounding baseline
    # 2. Parabolic: burst_min < surrounding baseline
    # 3. Other: burst_min ≈ surrounding baseline

    #Compares the minimum voltage of the burst to the mean voltage before and after the burst.
    
    square_wave_bursts = []
    parabolic_bursts = []
    other_bursts = []

    for i, (burst_start, burst_end) in enumerate(bursts):
        burst_mask = (time >= burst_start) & (time <= burst_end)
        burst_min = np.min(signal[burst_mask])

        # Compute mean of signal before and after the burst
        prev_mean = np.mean(signal[(time > bursts[i-1][1]) & (time < burst_start)]) if i > 0 else np.nan
        next_mean = np.mean(signal[(time > burst_end) & (time < bursts[i+1][0])]) if i < len(bursts)-1 else np.nan
        inter_mean = np.nanmean([prev_mean, next_mean])

        # Classify based on burst minimum relative to surrounding mean
        if burst_min > inter_mean:
            square_wave_bursts.append((burst_start, burst_end))
        elif burst_min < inter_mean:
            parabolic_bursts.append((burst_start, burst_end))
        else:
            other_bursts.append((burst_start, burst_end))

    return square_wave_bursts, parabolic_bursts, other_bursts

def extract_normalized_bursts(burst_list, signal, time, n_points=100):
    
    # Extract bursts and normalize them for machine learning (shapelet learning):
    # - X-axis (time) is rescaled to n_points
    # - Y-axis (amplitude) is z-score normalized
    # Returns a list of normalized arrays.

    normalized_bursts = []
    for start, end in burst_list:
        mask = (time >= start) & (time <= end)
        t_burst = time[mask]
        s_burst = signal[mask]

        s_rescaled = rescale_x(t_burst, s_burst, n_points=n_points)  # Rescale duration
        s_normalized = normalize_y(s_rescaled)                        # Normalize amplitude

        normalized_bursts.append(s_normalized)
    return normalized_bursts


# Load the signal 
file_path = "bursting/cell89basal.abf"
abf = pyabf.ABF(file_path)

# Concatenate all sweeps to create a single continuous signal
signal = np.concatenate([abf.setSweep(i) or abf.sweepY for i in range(abf.sweepCount)])
dt = 1.0 / abf.dataRate  # Sampling interval
time = np.arange(len(signal)) * dt

# Detect spikes and bursts 
spike_indices = detect_spikes(signal)  # Find all spike indices
spike_times = time[spike_indices]      # Convert indices to time

bursts = detect_bursts(spike_times)    # Detect bursts based on ISI

# Classify bursts 
square_wave_bursts, parabolic_bursts, other_bursts = classify_bursts(bursts, signal, time)

# Extract normalized bursts for shapelet learning 
n_points = 100  # Number of points for rescaling each burst
square_bursts_normalized = extract_normalized_bursts(square_wave_bursts, signal, time, n_points)
parabolic_bursts_normalized = extract_normalized_bursts(parabolic_bursts, signal, time, n_points)
other_bursts_normalized = extract_normalized_bursts(other_bursts, signal, time, n_points)

# Combine all normalized bursts into a single dataset
all_normalized_bursts = square_bursts_normalized + parabolic_bursts_normalized + other_bursts_normalized
labels = ([0]*len(square_bursts_normalized) +    # Label 0 = Square Wave
          [1]*len(parabolic_bursts_normalized) + # Label 1 = Parabolic
          [2]*len(other_bursts_normalized))      # Label 2 = Other

# Imports 
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from tslearn.preprocessing import TimeSeriesScalerMinMax
from tslearn.shapelets import LearningShapelets
from tensorflow.keras.optimizers import Adam

# Prepare data 
# "all_normalized_bursts" and "labels" should come from your signal preprocessing
# Convert to 3D array (n_samples, time_series_length, 1)
X = np.array(all_normalized_bursts)[:, :, np.newaxis]
y = np.array(labels)

# Normalize each burst to the [0, 1] range for shapelet learning
X = TimeSeriesScalerMinMax().fit_transform(X)

# Shapelet model configuration 
# We specify 2 shapelets per time series size (here the burst length)
n_shapelets_per_size = {X.shape[1]: 2}

shp_clf = LearningShapelets(
    n_shapelets_per_size=n_shapelets_per_size,
    weight_regularizer=0.0001,    # L2 regularization to prevent overfitting
    optimizer=Adam(0.01),         # Optimizer for training shapelets
    max_iter=300,                  # Maximum number of iterations
    verbose=0,                     # No console output
    scale=False,                   # Shapelets are not scaled automatically
    random_state=42
)

# Train shapelet model 
shp_clf.fit(X, y)  # Learn shapelets from normalized bursts

# Transform bursts to 2D distance space 
# Each burst is represented by its distance to each learned shapelet
distances = shp_clf.transform(X).reshape((-1, 2))  # 2 shapelets → 2D

# 2D Visualization setup 
%matplotlib inline
viridis = cm.get_cmap('viridis', 4)  # Color map for 4 classes
fig = plt.figure(constrained_layout=True, figsize=(10,6))
gs = fig.add_gridspec(3, 9)
fig_ax1 = fig.add_subplot(gs[0, :2])    # First shapelet plot
fig_ax2 = fig.add_subplot(gs[0, 2:4])   # Second shapelet plot
fig_ax4 = fig.add_subplot(gs[:, 4:])    # 2D scatter plot of transformed bursts

# Plot learned shapelets 
fig_ax1.plot(shp_clf.shapelets_[0].flatten())
fig_ax1.set_title('Shapelet $\\mathbf{s}_1$')
fig_ax2.plot(shp_clf.shapelets_[1].flatten())
fig_ax2.set_title('Shapelet $\\mathbf{s}_2$')

# Scatter plot of distance-transformed bursts 
for i, label in enumerate(np.unique(y)):
    mask = y == label
    fig_ax4.scatter(
        distances[mask][:,0],  # Distance to shapelet 1
        distances[mask][:,1],  # Distance to shapelet 2
        c=[viridis(i / max(1, len(np.unique(y)) - 1))]*np.sum(mask),  # Color per class
        edgecolors='k',
        label=f'Class {label}'
    )

# Compute decision boundaries 
xmin, xmax = distances[:,0].min()-0.1, distances[:,0].max()+0.1
ymin, ymax = distances[:,1].min()-0.1, distances[:,1].max()+0.1
xx, yy = np.meshgrid(
    np.linspace(xmin, xmax, 200),
    np.linspace(ymin, ymax, 200)
)

# Get the learned weights and biases of the classification layer
W, b = shp_clf.model_.get_layer("classification").get_weights()
n_classes = len(np.unique(y))

# Compute predictions over the grid for contour plotting
Z = []
for x_val, y_val in np.c_[xx.ravel(), yy.ravel()]:
    if n_classes == 2:
        # Binary classification using linear decision boundary
        logit = b[0] + W[0,0]*x_val + W[1,0]*y_val
        pred = int(logit >= 0)
    else:
        # Multiclass classification: choose class with highest score
        scores = [b[i] + W[0,i]*x_val + W[1,i]*y_val for i in range(n_classes)]
        pred = np.argmax(scores)
    Z.append(pred)

Z = np.array(Z).reshape(xx.shape)
fig_ax4.contourf(xx, yy, Z/max(1, n_classes-1), cmap=viridis, alpha=0.25)

# Labels and aesthetics 
fig_ax4.set_xlabel('$d(\\mathbf{x}, \\mathbf{s}_1)$')  # Distance to shapelet 1
fig_ax4.set_ylabel('$d(\\mathbf{x}, \\mathbf{s}_2)$')  # Distance to shapelet 2
fig_ax4.set_xlim(xmin, xmax)
fig_ax4.set_ylim(ymin, ymax)
fig_ax4.set_title('Distance-transformed bursts')
fig_ax4.legend()
plt.show()
