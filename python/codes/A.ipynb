{
  "repository_config": {
    "name": "Time-Series-Shapelet-Classification",
    "description": "A repository for time series classification using the Learning Shapelets algorithm, based on the provided Jupyter Notebook.",
    "license": "MIT",
    "main_language": "Python",
    "explanation": "This object defines the high-level configuration and metadata for the GitHub repository."
  },
  "files": [
    {
      "file_path": "README.md",
      "purpose": "Project documentation, setup instructions, and examples.",
      "content_type": "markdown",
      "explanation": "The README is the repository's entry point. It should explain the shapelet method, how to install dependencies (from requirements.txt), and how to run the main script. It can also include visualizations of the learned shapelets for interpretability."
    },
    {
      "file_path": "requirements.txt",
      "purpose": "Lists all necessary Python packages and their versions to ensure environment reproducibility.",
      "content_type": "text/plain",
      "example_content": [
        "numpy",
        "pandas",
        "scikit-learn",
        "tslearn>=0.10.0",
        "matplotlib"
      ],
      "explanation": "The 'tslearn' library is essential for the Learning Shapelets model. Users can install all dependencies with 'pip install -r requirements.txt'."
    },
    {
      "file_path": "src/shapelets_analysis.py",
      "purpose": "The primary Python script containing the shapelet model definition, training, and evaluation logic.",
      "content_type": "python",
      "explanation": "This is the core code modularized from your Jupyter Notebook. It includes detailed, English-language comments on data handling, model configuration, and performance metrics.",
      "code_content": "# ==============================================================================\n# shapelets_analysis.py - Core Time Series Shapelet Analysis Script\n# This script implements the Learning Shapelets Classifier using the tslearn library.\n# ==============================================================================\n\n# --- IMPORTS AND CONFIGURATION ---\n\n# Import standard data handling and numerical libraries\nimport numpy as np # Used for efficient array and matrix operations.\nimport pandas as pd # Used for data loading, cleaning, and time series indexing (if needed).\n\n# Import machine learning libraries\n# tslearn is a dedicated library for time series machine learning, providing the shapelet implementation.\n# scikit-learn (sklearn) is standard for classification tools and metrics.\nfrom tslearn.shapelets import LearningShapeletsClassifier # The core shapelet model\nfrom tslearn.datasets import UCR_UEA_datasets # Utility for loading standard time series datasets (for testing).\nfrom sklearn.model_selection import train_test_split # Split data into training and testing sets.\nfrom sklearn.metrics import classification_report, accuracy_score # Evaluate model performance.\n\n# Visualization libraries (for plotting time series and shapelets)\nimport matplotlib.pyplot as plt\n\n# --- CONSTANTS AND DATA LOADING ---\n\n# Define a constant for the random state to ensure reproducibility of results\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE) # Set seed for NumPy operations.\n\n# Explanation: Load the time series data. Replace 'Trace' with your actual dataset name or loading function.\n# Time series data must be a 3D NumPy array: (n_samples, n_timestamps, n_features)\ntry:\n    # Example: Loading a common dataset (Trace) from tslearn utilities for demonstration\n    X_train, y_train, X_test, y_test = UCR_UEA_datasets().load_dataset('Trace')\nexcept ValueError:\n    # Fallback/placeholder for custom data (EDIT THIS BLOCK for your real data loading logic)\n    print(\"Loading placeholder data: Replace with actual data loading logic.\")\n    X_train = np.random.rand(50, 100, 1) # 50 samples, 100 time steps, 1 feature\n    y_train = np.random.randint(0, 2, 50)\n    X_test = np.random.rand(50, 100, 1)\n    y_test = np.random.randint(0, 2, 50)\n\n# Check the input shapes (Essential for time series modeling)\nprint(f\"Train data shape: {X_train.shape}\")\nprint(f\"Train labels shape: {y_train.shape}\")\n\n# --- MODEL PARAMETER CONFIGURATION ---\n\n# Explanation: Shapelets are short, discriminative sub-sequences. The model learns these patterns.\n# The min/max lengths define the search space for these sub-sequences, which is crucial for performance.\n\nmax_ts_length = X_train.shape[1]\n# Example: Search for shapelets between 10% and 50% of the total time series length\nshapelet_lengths = [int(max_ts_length * 0.1), int(max_ts_length * 0.5)]\n\n# n_shapelets: Total number of shapelets to learn across all classes.\n# A common starting point is usually 5-10 shapelets per class.\nn_classes = len(np.unique(y_train))\nn_shapelets = n_classes * 5\n\n# --- MODEL INITIALIZATION AND TRAINING ---\n\n# Explanation: Initialize the LearningShapeletsClassifier with key hyper-parameters.\n# The model uses the distances between the time series and the learned shapelets \n# as features for a final classification layer (e.g., logistic regression).\n\ntsc_shapelets = LearningShapeletsClassifier(\n    n_shapelets=n_shapelets, # Total number of shapelets to learn\n    shapelet_lengths=shapelet_lengths, # Range of lengths [min, max]\n    optimizer=\"adam\", # Optimization algorithm for training the shapelets' weights\n    learning_rate=0.01, # Step size for the optimizer\n    max_iter=200, # Number of training epochs (may need to be adjusted for convergence)\n    tol=1e-4, # Tolerance for early stopping criterion\n    verbose=1, # Print training logs (Set to 0 for silent operation)\n    random_state=RANDOM_STATE\n)\n\n# Train the shapelet model\nprint(\"Starting model training...\")\ntsc_shapelets.fit(X_train, y_train)\nprint(\"Model training complete.\")\n\n# --- EVALUATION ---\n\n# Explanation: Evaluate the model on the held-out test set to gauge generalization performance.\ny_pred = tsc_shapelets.predict(X_test)\n\n# Calculate and print the overall accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"\\n--- Model Evaluation ---\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# Print a detailed classification report (Precision, Recall, F1-Score)\nprint(classification_report(y_test, y_pred))\n\n# --- SHAPELET VISUALIZATION (Conceptual) ---\n\n# Explanation: This block demonstrates how to access and visualize the learned shapelets.\n# This visualization is crucial for interpretability, showing which patterns \n# in the time series are key to the classification decision.\n\ndef visualize_shapelets(classifier):\n    \"\"\"Function to visualize the learned shapelets.\"\"\"\n    # The learned shapelets are available in the model's 'shapelets_' attribute\n    shapelets = classifier.shapelets_\n\n    n_shapelets_total = shapelets.shape[0]\n    cols = min(4, n_shapelets_total)\n    rows = int(np.ceil(n_shapelets_total / cols))\n\n    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3 * rows))\n    fig.suptitle(\"Learned Shapelets (Visualizing Key Patterns)\", fontsize=16)\n\n    for i, ax in enumerate(axes.flat):\n        if i < n_shapelets_total:\n            # Plot the shapelet. Squeeze removes the feature dimension (1) for 1D time series\n            ax.plot(shapelets[i].squeeze(), color='blue')\n            ax.set_title(f\"Shapelet {i+1}\")\n        else:\n            ax.axis('off') # Hide unused subplots\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout for suptitle\n    plt.show()\n\n# To run the visualization, uncomment the line below:\n# visualize_shapelets(tsc_shapelets)\n\n# ==============================================================================\n# END OF SCRIPT\n# ==============================================================================\n"
    },
    {
      "file_path": "notebooks/Shapelets.ipynb",
      "purpose": "The original Jupyter Notebook used for interactive development.",
      "content_type": "application/vnd.jupyter",
      "explanation": "The original notebook is preserved in a dedicated folder to maintain development history and interactive outputs."
    }
  ],
  "next_steps_for_user": {
    "explanation": "This JSON structure outlines the necessary files for a robust GitHub repository. Your next step should be to create these files in your local repository and commit them to GitHub.",
    "todo": [
      "Create the `src/` folder and the `shapelets_analysis.py` file, pasting the `code_content`.",
      "Create the `requirements.txt` file using the `example_content` list.",
      "Write a descriptive `README.md` to explain the project and its results."
    ]
  }
}
